{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = YOLO(\"./Yolo_models/bottle_detection_model/weights/best.pt\")\n",
    "model2 = YOLO(\"./Yolo_models/Blood/weights/best.pt\")\n",
    "model3 = YOLO(\"./Yolo_models/License_Plate/weights/best.pt\")\n",
    "model4 = YOLO(\"./Yolo_models/Smoke/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./Inputs/bl.jpeg\"\n",
    "OUTPUT_DIR = \"./Outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully.\n",
      "Video FPS: 30.0\n",
      "Processing at 10 FPS, skipping every 3 frames\n",
      "\n",
      "0: 640x640 (no detections), 226.3ms\n",
      "Speed: 5.9ms preprocess, 226.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 230.7ms\n",
      "Speed: 3.4ms preprocess, 230.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 258.2ms\n",
      "Speed: 4.5ms preprocess, 258.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 276.8ms\n",
      "Speed: 4.8ms preprocess, 276.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 214.4ms\n",
      "Speed: 3.9ms preprocess, 214.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 224.5ms\n",
      "Speed: 4.3ms preprocess, 224.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 227.2ms\n",
      "Speed: 3.5ms preprocess, 227.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 226.4ms\n",
      "Speed: 11.5ms preprocess, 226.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 258.2ms\n",
      "Speed: 3.8ms preprocess, 258.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 219.8ms\n",
      "Speed: 4.2ms preprocess, 219.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 199.1ms\n",
      "Speed: 3.3ms preprocess, 199.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 200.9ms\n",
      "Speed: 4.9ms preprocess, 200.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 221.3ms\n",
      "Speed: 3.5ms preprocess, 221.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 250.2ms\n",
      "Speed: 4.7ms preprocess, 250.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 276.3ms\n",
      "Speed: 4.5ms preprocess, 276.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 235.6ms\n",
      "Speed: 6.0ms preprocess, 235.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 231.0ms\n",
      "Speed: 4.2ms preprocess, 231.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 272.4ms\n",
      "Speed: 5.4ms preprocess, 272.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 276.6ms\n",
      "Speed: 3.8ms preprocess, 276.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 233.2ms\n",
      "Speed: 5.2ms preprocess, 233.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 283.5ms\n",
      "Speed: 4.8ms preprocess, 283.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 228.7ms\n",
      "Speed: 4.6ms preprocess, 228.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 269.7ms\n",
      "Speed: 4.6ms preprocess, 269.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 260.0ms\n",
      "Speed: 7.7ms preprocess, 260.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 248.2ms\n",
      "Speed: 4.2ms preprocess, 248.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 261.3ms\n",
      "Speed: 4.5ms preprocess, 261.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 225.8ms\n",
      "Speed: 4.7ms preprocess, 225.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 206.8ms\n",
      "Speed: 3.7ms preprocess, 206.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 214.5ms\n",
      "Speed: 4.8ms preprocess, 214.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 200.7ms\n",
      "Speed: 3.8ms preprocess, 200.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 231.9ms\n",
      "Speed: 4.0ms preprocess, 231.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 241.1ms\n",
      "Speed: 4.0ms preprocess, 241.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 254.7ms\n",
      "Speed: 5.5ms preprocess, 254.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Error: Failed to read frame 97.\n",
      "Output video saved to: ./Outputs/temp.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model_path = './Yolo_models/Smoke/weights/best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "video_path = './Inputs/temp.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video file.\")\n",
    "else:\n",
    "    print(\"Video opened successfully.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Video FPS: {fps}\")\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_video_path = './Outputs/temp.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "desired_fps = 10\n",
    "frame_interval = int(fps // desired_fps)\n",
    "\n",
    "print(f\"Processing at {desired_fps} FPS, skipping every {frame_interval} frames\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Error: Failed to read frame {frame_count}.\")\n",
    "        break\n",
    "\n",
    "    if frame_count % frame_interval != 0:\n",
    "        frame_count += 1\n",
    "        continue\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (640, 640))\n",
    "\n",
    "    results = model.predict(source=resized_frame, conf=0.3)\n",
    "\n",
    "    result_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    disclaimer_text = \"Smoking is injurious to health\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 3  # Increase font scale for a bigger text size\n",
    "    text_size = cv2.getTextSize(disclaimer_text, font, font_scale, 2)[0]\n",
    "    text_width = text_size[0]\n",
    "    text_height = text_size[1]\n",
    "\n",
    "    text_x = (frame_width - text_width) // 2\n",
    "    text_y = frame_height - 20\n",
    "\n",
    "    cv2.putText(result_frame, disclaimer_text, (text_x, text_y), font, font_scale, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(cv2.cvtColor(result_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Output video saved to: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
