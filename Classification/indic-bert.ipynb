{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-13T05:07:11.840009Z",
     "iopub.status.busy": "2025-03-13T05:07:11.839731Z",
     "iopub.status.idle": "2025-03-13T05:07:23.149538Z",
     "shell.execute_reply": "2025-03-13T05:07:23.148834Z",
     "shell.execute_reply.started": "2025-03-13T05:07:11.839987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:15:25.294543Z",
     "iopub.status.busy": "2025-03-13T05:15:25.294224Z",
     "iopub.status.idle": "2025-03-13T05:15:25.297839Z",
     "shell.execute_reply": "2025-03-13T05:15:25.297038Z",
     "shell.execute_reply.started": "2025-03-13T05:15:25.294514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:10:50.065728Z",
     "iopub.status.busy": "2025-03-13T05:10:50.065393Z",
     "iopub.status.idle": "2025-03-13T05:10:50.069254Z",
     "shell.execute_reply": "2025-03-13T05:10:50.068529Z",
     "shell.execute_reply.started": "2025-03-13T05:10:50.065704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:07:56.304242Z",
     "iopub.status.busy": "2025-03-13T05:07:56.303794Z",
     "iopub.status.idle": "2025-03-13T05:07:56.316869Z",
     "shell.execute_reply": "2025-03-13T05:07:56.316014Z",
     "shell.execute_reply.started": "2025-03-13T05:07:56.304218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:10:58.551179Z",
     "iopub.status.busy": "2025-03-13T05:10:58.550905Z",
     "iopub.status.idle": "2025-03-13T05:10:58.555480Z",
     "shell.execute_reply": "2025-03-13T05:10:58.554625Z",
     "shell.execute_reply.started": "2025-03-13T05:10:58.551159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Cleans text by removing unwanted symbols, URLs, HTML, and numbers.\"\"\"\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text inside brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', ' ', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:10:56.112264Z",
     "iopub.status.busy": "2025-03-13T05:10:56.111991Z",
     "iopub.status.idle": "2025-03-13T05:10:56.117564Z",
     "shell.execute_reply": "2025-03-13T05:10:56.116761Z",
     "shell.execute_reply.started": "2025-03-13T05:10:56.112243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower()\n",
    "\n",
    "def replace_all_caps(tokens: List[str]) -> List[str]:\n",
    "    return [f'xxup {t.lower()}' if t.isupper() else t for t in tokens]\n",
    "\n",
    "def deal_caps(tokens: List[str]) -> List[str]:\n",
    "    return [f'xxmaj {t}' if t.istitle() else t for t in tokens]\n",
    "\n",
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:11:01.219961Z",
     "iopub.status.busy": "2025-03-13T05:11:01.219673Z",
     "iopub.status.idle": "2025-03-13T05:11:01.223326Z",
     "shell.execute_reply": "2025-03-13T05:11:01.222645Z",
     "shell.execute_reply.started": "2025-03-13T05:11:01.219937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "custom_pre_rules = [lower_case_everything, handle_all_caps, handle_upper_case_first_letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:11:03.460727Z",
     "iopub.status.busy": "2025-03-13T05:11:03.460423Z",
     "iopub.status.idle": "2025-03-13T05:11:03.464281Z",
     "shell.execute_reply": "2025-03-13T05:11:03.463629Z",
     "shell.execute_reply.started": "2025-03-13T05:11:03.460703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    text = clean_text(str(text))\n",
    "    for rule in custom_pre_rules:\n",
    "        text = rule(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:11:46.243518Z",
     "iopub.status.busy": "2025-03-13T05:11:46.243211Z",
     "iopub.status.idle": "2025-03-13T05:11:46.247751Z",
     "shell.execute_reply": "2025-03-13T05:11:46.246862Z",
     "shell.execute_reply.started": "2025-03-13T05:11:46.243489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    unwanted_labels = {'OFf','label','not'}\n",
    "    df = df[~df['category'].isin(unwanted_labels)]\n",
    "    label_mapping = {\n",
    "        \"NOT\" : 0,\n",
    "        \"OFF\" : 1\n",
    "    }\n",
    "    df[\"category\"] = df[\"category\"].map(label_mapping)\n",
    "    df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:12:13.425814Z",
     "iopub.status.busy": "2025-03-13T05:12:13.425512Z",
     "iopub.status.idle": "2025-03-13T05:12:13.431047Z",
     "shell.execute_reply": "2025-03-13T05:12:13.430244Z",
     "shell.execute_reply.started": "2025-03-13T05:12:13.425792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TanglishDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Use the tokenizer to handle Tanglish text properly\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:12:29.541213Z",
     "iopub.status.busy": "2025-03-13T05:12:29.540929Z",
     "iopub.status.idle": "2025-03-13T05:12:29.549201Z",
     "shell.execute_reply": "2025-03-13T05:12:29.548271Z",
     "shell.execute_reply.started": "2025-03-13T05:12:29.541192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=5):\n",
    "    # Set up optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_accuracy = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                val_accuracy += (preds == labels).sum().item()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_accuracy /= len(val_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Val Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_tanglish_model.pt')\n",
    "            \n",
    "            # Print classification report\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(val_true, val_preds))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:12:45.679853Z",
     "iopub.status.busy": "2025-03-13T05:12:45.679539Z",
     "iopub.status.idle": "2025-03-13T05:12:45.685193Z",
     "shell.execute_reply": "2025-03-13T05:12:45.684534Z",
     "shell.execute_reply.started": "2025-03-13T05:12:45.679826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_accuracy = 0\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            test_accuracy += (preds == labels).sum().item()\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(classification_report(test_true, test_preds))\n",
    "    \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T09:24:06.251615Z",
     "iopub.status.busy": "2025-03-13T09:24:06.250611Z",
     "iopub.status.idle": "2025-03-13T09:24:06.257468Z",
     "shell.execute_reply": "2025-03-13T09:24:06.256630Z",
     "shell.execute_reply.started": "2025-03-13T09:24:06.251571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_hate_speech(text, model, tokenizer, device, max_len=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'prediction': prediction,\n",
    "        'confidence': probs[0][prediction].item(),\n",
    "        'result': 'Hate Speech' if prediction == 1 else 'Not Hate Speech'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:14:32.456033Z",
     "iopub.status.busy": "2025-03-13T05:14:32.455716Z",
     "iopub.status.idle": "2025-03-13T05:14:32.463581Z",
     "shell.execute_reply": "2025-03-13T05:14:32.462674Z",
     "shell.execute_reply.started": "2025-03-13T05:14:32.456007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = '/kaggle/input/main-dataset/main_dataset.csv'  # Replace with your dataset path\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    # Split the data\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "    \n",
    "    print(f\"Training set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "   \n",
    "    model_name = \"ai4bharat/indic-bert\"  \n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TanglishDataset(\n",
    "        texts=train_df['text'].values,\n",
    "        labels=train_df['category'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    val_dataset = TanglishDataset(\n",
    "        texts=val_df['text'].values,\n",
    "        labels=val_df['category'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    test_dataset = TanglishDataset(\n",
    "        texts=test_df['text'].values,\n",
    "        labels=test_df['category'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(model, train_loader, val_loader, device, epochs=5)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_tanglish_model.pt'))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Example prediction\n",
    "    print(\"\\nExample predictions:\")\n",
    "    sample_texts = [\n",
    "        \"Intha post romba useful iruku, thanks for sharing!\",  # Expected: Not Hate\n",
    "        \"Nee oru useless paiyan, engaluku vendam\"  # Expected: Hate\n",
    "    ]\n",
    "    \n",
    "    for text in sample_texts:\n",
    "        result = predict_hate_speech(text, model, tokenizer, device)\n",
    "        print(f\"Text: {result['text']}\")\n",
    "        print(f\"Prediction: {result['result']} (Confidence: {result['confidence']:.4f})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-13T05:15:30.081921Z",
     "iopub.status.busy": "2025-03-13T05:15:30.081634Z",
     "iopub.status.idle": "2025-03-13T05:33:23.744562Z",
     "shell.execute_reply": "2025-03-13T05:33:23.743558Z",
     "shell.execute_reply.started": "2025-03-13T05:15:30.081899Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 9540\n",
      "Validation set size: 1061\n",
      "Test set size: 2651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b417a07f156940cb8a20c8b80cdff062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a989a1c7fec4a85b9889264c914b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0881b8d9044b88ad3ea403af5fa706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training model...\n",
      "Epoch 1/5:\n",
      "  Train Loss: 0.4930\n",
      "  Val Accuracy: 0.8615\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       605\n",
      "           1       0.90      0.77      0.83       456\n",
      "\n",
      "    accuracy                           0.86      1061\n",
      "   macro avg       0.87      0.85      0.86      1061\n",
      "weighted avg       0.86      0.86      0.86      1061\n",
      "\n",
      "Epoch 2/5:\n",
      "  Train Loss: 0.2799\n",
      "  Val Accuracy: 0.8483\n",
      "Epoch 3/5:\n",
      "  Train Loss: 0.2088\n",
      "  Val Accuracy: 0.8897\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       605\n",
      "           1       0.94      0.79      0.86       456\n",
      "\n",
      "    accuracy                           0.89      1061\n",
      "   macro avg       0.90      0.88      0.88      1061\n",
      "weighted avg       0.90      0.89      0.89      1061\n",
      "\n",
      "Epoch 4/5:\n",
      "  Train Loss: 0.1442\n",
      "  Val Accuracy: 0.9095\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.92       605\n",
      "           1       0.85      0.96      0.90       456\n",
      "\n",
      "    accuracy                           0.91      1061\n",
      "   macro avg       0.91      0.92      0.91      1061\n",
      "weighted avg       0.92      0.91      0.91      1061\n",
      "\n",
      "Epoch 5/5:\n",
      "  Train Loss: 0.0980\n",
      "  Val Accuracy: 0.9255\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       605\n",
      "           1       0.89      0.94      0.92       456\n",
      "\n",
      "    accuracy                           0.93      1061\n",
      "   macro avg       0.92      0.93      0.92      1061\n",
      "weighted avg       0.93      0.93      0.93      1061\n",
      "\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Accuracy: 0.9208\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      1533\n",
      "           1       0.89      0.93      0.91      1118\n",
      "\n",
      "    accuracy                           0.92      2651\n",
      "   macro avg       0.92      0.92      0.92      2651\n",
      "weighted avg       0.92      0.92      0.92      2651\n",
      "\n",
      "\n",
      "Example predictions:\n",
      "Text: Intha post romba useful iruku, thanks for sharing!\n",
      "Prediction: Not Hate Speech (Confidence: 0.9989)\n",
      "\n",
      "Text: Nee oru useless paiyan, engaluku vendam\n",
      "Prediction: Hate Speech (Confidence: 0.8171)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ratish03/indic-BERT-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:41:30.281890Z",
     "iopub.status.busy": "2025-03-13T05:41:30.281591Z",
     "iopub.status.idle": "2025-03-13T05:41:30.285345Z",
     "shell.execute_reply": "2025-03-13T05:41:30.284682Z",
     "shell.execute_reply.started": "2025-03-13T05:41:30.281867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "a = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:41:32.013188Z",
     "iopub.status.busy": "2025-03-13T05:41:32.012940Z",
     "iopub.status.idle": "2025-03-13T05:41:37.708109Z",
     "shell.execute_reply": "2025-03-13T05:41:37.707202Z",
     "shell.execute_reply.started": "2025-03-13T05:41:32.013168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a76e3e156c4d7b870caa28ee8c8055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "best_tanglish_model.pt:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder,login\n",
    "\n",
    "username = \"ratish03\"\n",
    "repo_name = \"indic-BERT-Classification\"\n",
    "\n",
    "api = HfApi()\n",
    "token = a\n",
    "\n",
    "login(token=token)\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/kaggle/working/best_tanglish_model.pt\",\n",
    "    path_in_repo = \"best_tanglish_model.pt\",\n",
    "    repo_id = f\"{username}/{repo_name}\",\n",
    "    token=token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Files uploaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T09:14:11.788741Z",
     "iopub.status.busy": "2025-03-13T09:14:11.788312Z",
     "iopub.status.idle": "2025-03-13T09:14:12.570047Z",
     "shell.execute_reply": "2025-03-13T09:14:12.569424Z",
     "shell.execute_reply.started": "2025-03-13T09:14:11.788700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T09:18:27.971717Z",
     "iopub.status.busy": "2025-03-13T09:18:27.971394Z",
     "iopub.status.idle": "2025-03-13T09:18:28.084386Z",
     "shell.execute_reply": "2025-03-13T09:18:28.083722Z",
     "shell.execute_reply.started": "2025-03-13T09:18:27.971691Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /root/.cache/huggingface/hub/models--ratish03--indic-BERT-Classification/snapshots/a8f57f4af295c391ff35cbe27536790956eb5a8d/best_tanglish_model.pt\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "repo_id = \"ratish03/indic-BERT-Classification\"\n",
    "\n",
    "# Download the model file\n",
    "model_path = hf_hub_download(repo_id=repo_id, filename=\"best_tanglish_model.pt\")\n",
    "print(f\"Model downloaded to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-13T09:23:07.897679Z",
     "iopub.status.busy": "2025-03-13T09:23:07.897332Z",
     "iopub.status.idle": "2025-03-13T09:23:36.948680Z",
     "shell.execute_reply": "2025-03-13T09:23:36.947689Z",
     "shell.execute_reply.started": "2025-03-13T09:23:07.897652Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186bbd075f9242229a03543f954d144d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd9249f88e243468b955bd42546e485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76cbedc39e740d9b7a97beca0237903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: \"https://huggingface.co/ratish03/indic-BERT-Classification/resolve/main/best_tanglish_model.pt\" to /root/.cache/torch/hub/checkpoints/best_tanglish_model.pt\n",
      "100%|██████████| 128M/128M [00:02<00:00, 55.9MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertSdpaAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"ai4bharat/indic-bert\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load fine-tuned model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Load fine-tuned weights from Hugging Face\n",
    "model_path = \"ratish03/indic-BERT-Classification\"  # Update this with your actual model path\n",
    "model.load_state_dict(torch.hub.load_state_dict_from_url(f\"https://huggingface.co/{model_path}/resolve/main/best_tanglish_model.pt\"))\n",
    "\n",
    "# Move model to the correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T09:26:55.653602Z",
     "iopub.status.busy": "2025-03-13T09:26:55.653303Z",
     "iopub.status.idle": "2025-03-13T09:26:55.768162Z",
     "shell.execute_reply": "2025-03-13T09:26:55.767249Z",
     "shell.execute_reply.started": "2025-03-13T09:26:55.653570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: thevidiyaaaan\n",
      "Prediction: Hate Speech (Confidence: 0.9986)\n",
      "\n",
      "Text: mutti\n",
      "Prediction: Not Hate Speech (Confidence: 0.6793)\n",
      "\n",
      "Text: thampi\n",
      "Prediction: Not Hate Speech (Confidence: 0.9711)\n",
      "\n",
      "Text: theriyum\n",
      "Prediction: Not Hate Speech (Confidence: 0.7640)\n",
      "\n",
      "Text: okkanum\n",
      "Prediction: Hate Speech (Confidence: 0.7707)\n",
      "\n",
      "Text: kuthi\n",
      "Prediction: Hate Speech (Confidence: 0.9533)\n",
      "\n",
      "Text: koothiya\n",
      "Prediction: Hate Speech (Confidence: 0.9524)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\"thevidiyaaaan\",\"mutti\",\"thampi\",\"theriyum\",\"okkanum\",\"kuthi\",\"koothiya\"]\n",
    "\n",
    "for text in sample_texts:\n",
    "    result = predict_hate_speech(text, model, tokenizer, device)\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Prediction: {result['result']} (Confidence: {result['confidence']:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6795890,
     "sourceId": 10929786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
