{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import faster_whisper\n",
    "from transformers import pipeline\n",
    "import pickle\n",
    "from typing import List\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from itertools import product\n",
    "from scipy.signal import butter, lfilter\n",
    "from collections import deque\n",
    "from pydub import AudioSegment\n",
    "from pydub.generators import Sine\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highpass_filter(y, sr, cutoff=100):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(1, normal_cutoff, btype='high', analog=False)\n",
    "    return lfilter(b, a, y)\n",
    "\n",
    "def preprocess_audio(input_audio):\n",
    "    y, sr = librosa.load(input_audio, sr=16000)\n",
    "    y_filtered = highpass_filter(y,sr)\n",
    "    reduced_noise = nr.reduce_noise(y=y_filtered, sr=sr,prop_decrease=1.0)\n",
    "    \n",
    "    # Generate cleaned file name dynamically\n",
    "    file_name = os.path.splitext(os.path.basename(input_audio))[0]\n",
    "    output_wav = f\"./Cleaned_audio/{file_name}_cleaned.wav\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_wav), exist_ok=True)\n",
    "    \n",
    "    sf.write(output_wav, reduced_noise, sr)\n",
    "    print(\"Audio Cleaned Successfully\")\n",
    "    return output_wav\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    segments, _ = model.transcribe(audio_file, language=\"ta\", word_timestamps=True)\n",
    "    print(\"Translated audio to tamil texts successfully\")\n",
    "    result = []\n",
    "    #tan_texts = []\n",
    "    for segment in segments:\n",
    "        for word in segment.words:\n",
    "            t = []\n",
    "            text = word.word\n",
    "            start_time = word.start\n",
    "            end_time = word.end\n",
    "            tanglish_text = translator(text, max_length=128)[0]['translation_text']\n",
    "            tanglish_text = tanglish_text.replace(\" \", \"\")\n",
    "            # if tanglish_text not in vocab_list:\n",
    "            #     tanglish_text = generate_spellings(tanglish_text,vocab_list)\n",
    "            # print(tanglish_text)\n",
    "            t.append(tanglish_text)\n",
    "            t.append(start_time)\n",
    "            t.append(end_time)\n",
    "            print(text,tanglish_text)\n",
    "            #tan_texts.append(tanglish_text)\n",
    "            result.append(t)\n",
    "            #print(tanglish_text,start_time,end_time)\n",
    "    print(\"Translated tamil to tanglish text successfully\")\n",
    "    return result\n",
    "\n",
    "# def predict_category(sample, tokenizer, preprocess_text, remove_single_characters, cv, clf):\n",
    "#     sample = preprocess_text(sample)\n",
    "#     sample_tokens = tokenizer.tokenizer([sample]) \n",
    "#     sample_tokens = remove_single_characters(sample_tokens[0])  \n",
    "#     sample_tokens = [\" \".join(sample_tokens)]  \n",
    "#     data = cv.transform(sample_tokens).toarray()\n",
    "#     predict = clf.predict(data)\n",
    "#     return 1 if predict[0] == 'OFF' else 0\n",
    "\n",
    "# def remove_single_characters(tokens: List[str]) -> List[str]:\n",
    "#     return [token for token in tokens if len(token) > 1]\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text inside brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', ' ', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    return text\n",
    "\n",
    "suffixes_to_remove = [\"da\", \"ga\", \"vaa\", \"ra\", \"la\", \"pa\", \"ma\", \"ta\", \"na\",\"p\",\"l\",\"i\"]\n",
    "\n",
    "def remove_suffix(word):\n",
    "    if word in vocab_list:\n",
    "        #print(\"Remove: \",word)\n",
    "        return word\n",
    "    for suffix in suffixes_to_remove:\n",
    "        if word.endswith(suffix):\n",
    "            a  =word[:-len(suffix)]\n",
    "            if a in vocab_list:\n",
    "                #print(\"Remove: \",word)\n",
    "                return word[:-len(suffix)]\n",
    "    #print(\"Remove: \",word)\n",
    "    return word\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = clean_text(str(text))\n",
    "    for rule in custom_pre_rules:\n",
    "        text = rule(text)\n",
    "    return text\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower()\n",
    "\n",
    "def replace_all_caps(tokens: List[str]) -> List[str]:\n",
    "    return [f'xxup {t.lower()}' if t.isupper() else t for t in tokens]\n",
    "\n",
    "def deal_caps(tokens: List[str]) -> List[str]:\n",
    "    return [f'xxmaj {t}' if t.istitle() else t for t in tokens]\n",
    "\n",
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def trim_repeated_letters(word: str) -> str:\n",
    "    a =  re.sub(r'(.)\\1+$', r'\\1', word)\n",
    "    #print(\"Trimmed: \",a)\n",
    "    return a\n",
    "\n",
    "custom_pre_rules = [lower_case_everything, handle_all_caps, handle_upper_case_first_letter]\n",
    "\n",
    "\n",
    "class CodeMixedTanglishTokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(model_path)\n",
    "    def __call__(self, items: List[str]) -> List[List[str]]:  \n",
    "        return [self.sp.EncodeAsPieces(t) for t in items]\n",
    "    def tokenizer(self, items: List[str]) -> List[List[str]]:\n",
    "        return [self.sp.EncodeAsPieces(t) for t in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "meta_model = load_model(\"Classification/meta_model_neural.h5\")\n",
    "scaler = joblib.load(\"Classification/scaler.pkl\")\n",
    "\n",
    "c_model_name = \"ai4bharat/indic-bert\"\n",
    "c_tokenizer = AutoTokenizer.from_pretrained(c_model_name)\n",
    "\n",
    "c_model = AutoModelForSequenceClassification.from_pretrained(c_model_name,num_labels=2)\n",
    "c_model_path = \"ratish03/indic-BERT-Classification\"\n",
    "c_model.load_state_dict(torch.hub.load_state_dict_from_url(f\"https://huggingface.co/{c_model_path}/resolve/main/best_tanglish_model.pt\",map_location=torch.device('cpu')))\n",
    "\n",
    "dev1 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "c_model.to(dev1)\n",
    "\n",
    "bilstm_model = load_model(\"./Classification/bilstm_model1.h5\")\n",
    "\n",
    "tokenizer = CodeMixedTanglishTokenizer(\"./Tokenizer/Tanglish/taen_spm.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Cleaned Successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "input_audio_path = \"Audio/tempo1.mp3\"\n",
    "clean_audio = preprocess_audio(input_audio_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = faster_whisper.WhisperModel(\"medium\", device=device, compute_type=\"float32\")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"Tokenizer/Tanglish/taen_spm.model\")\n",
    "vocab_size = sp.get_piece_size()\n",
    "vocab_list = [sp.id_to_piece(i) for i in range(vocab_size)]\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"ratish03/tamil_to_tanglish_model\", tokenizer=\"ratish03/tamil_to_tanglish_model\", src_lang=\"ta\", tgt_lang=\"en\")\n",
    "\n",
    "def predict_hate_speech(text, model, tokenizer, device, max_len=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'prediction': prediction,\n",
    "        'confidence': probs[0][prediction].item(),\n",
    "        'result': ['Hate Speech' if prediction == 1 else 'Not Hate Speech']\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_spellings(word, vocab_list, max_depth=5):\n",
    "    phonetic_mappings = {\n",
    "        \"aa\": [\"a\"], \"ae\": [\"e\"], \"ai\": [\"ay\", \"ei\"], \"au\": [\"ow\", \"av\"], \"ee\": [\"i\", \"ea\", \"e\"], \"i\": [\"e\"],\"u\":[\"oo\"],\n",
    "        \"oo\": [ \"ou\", \"o\"], \"e\": [\"i\"], \"oa\": [\"o\"], \"ua\": [\"wa\"], \"v\": [\"w\"], \"pa\": [\"ba\"], \"ka\": [\"ga\"],\n",
    "        \"tha\": [\"ta\"], \"thae\": [\"the\"], \"dha\": [\"da\"], \"zh\": [\"l\", \"r\"], \"sh\": [\"s\", \"ch\"], \"u\": [\"oo\"],\"t\":[\"d\"],\n",
    "        \"ch\": [\"sh\", \"s\"], \"ph\": [\"f\"], \"j\": [\"z\", \"y\"], \"cho\": [\"sho\", \"so\"], \"chu\": [\"shu\"], \"koa\": [\"go\"], \"ko\": [\"go\"], \"bi\": [\"pi\"],\n",
    "        \"che\": [\"she\"], \"ji\": [\"zi\"], \"jo\": [\"zo\"], \"ku\": [\"gu\"], \"kha\": [\"ka\"], \"ghe\": [\"ge\"], \"vai\": [\"vi\"], \"cha\": [\"sa\"], \"ga\": [\"\"], \"aa\": ['a']\n",
    "    }\n",
    "\n",
    "    def modify_and_check(word):\n",
    "        \"\"\"Generate modified versions and check if they exist in vocab_list.\"\"\"\n",
    "        word_parts = [[char] if char not in phonetic_mappings else [char] + phonetic_mappings[char] for char in word]\n",
    "        \n",
    "        for combo in product(*word_parts):\n",
    "            modified_word = \"\".join(combo)\n",
    "            if modified_word in vocab_list:\n",
    "                return modified_word\n",
    "        return None\n",
    "\n",
    "    queue = deque([(word, 0)])  # (word, depth)\n",
    "    visited = set([word])  # Keep track of visited words\n",
    "\n",
    "    while queue:\n",
    "        current_word, depth = queue.popleft()  # Pop from front (BFS)\n",
    "        \n",
    "        # Stop if we reach max depth\n",
    "        if depth > max_depth:\n",
    "            return word  # Return original word if no valid one found\n",
    "        \n",
    "        # Check if the modified word exists\n",
    "        found_word = modify_and_check(current_word)\n",
    "        if found_word:\n",
    "            return found_word  # Found a match, return it\n",
    "        \n",
    "        # Generate new words\n",
    "        for key in phonetic_mappings:\n",
    "            if key in current_word:\n",
    "                for replacement in phonetic_mappings[key]:\n",
    "                    new_word = current_word.replace(key, replacement, 1)  # Replace only once per iteration\n",
    "                    \n",
    "                    if new_word not in visited:\n",
    "                        visited.add(new_word)  # Mark as visited\n",
    "                        print(new_word,depth)\n",
    "                        queue.append((new_word, depth + 1))  # Add with incremented depth\n",
    "\n",
    "    return word  # If no match found, return original word\n",
    "\n",
    "def create_beep(duration_ms):\n",
    "    return Sine(1000).to_audio_segment(duration=duration_ms).apply_gain(-5)\n",
    "\n",
    "def beep(input_audio,timestamps):\n",
    "    audio = AudioSegment.from_file(input_audio)  \n",
    "\n",
    "    for start, end in timestamps:\n",
    "        st = int(start*1000)\n",
    "        en = int(end*1000)\n",
    "\n",
    "        if en > len(audio):\n",
    "            en = len(audio)\n",
    "        if st >= len(audio):\n",
    "            continue\n",
    "        \n",
    "        duration = en - st\n",
    "        beep_segment = create_beep(duration)\n",
    "        \n",
    "        silent_segment = AudioSegment.silent(duration=duration)\n",
    "        audio = audio[:st] + silent_segment + audio[en:]\n",
    "        \n",
    "        audio = audio.overlay(beep_segment, position=st)\n",
    "\n",
    "    file_name = os.path.splitext(os.path.basename(input_audio))[0]\n",
    "    output_audio = f\"./Censored_audio/{file_name}_censored.mp3\"\n",
    "\n",
    "    audio.export(output_audio, format=\"mp3\")\n",
    "    print(f\"Beeped audio saved as {output_audio}\")\n",
    "\n",
    "def predict_category1(bilstm_label, bilstm_confidence, bert_label, bert_confidence):\n",
    "    input_data = np.array([[bilstm_label, bilstm_confidence, bert_label, bert_confidence]])\n",
    "    input_data = scaler.transform(input_data)  # Normalize the input\n",
    "    prediction = meta_model.predict(input_data)\n",
    "    predicted_category = 1 if prediction[0] > 0.5 else 0  # Convert probability to class label\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_whisper:Processing audio with duration 00:05.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated audio to tamil texts successfully\n",
      " உம்புடா, umbudaa,\n",
      " உம்புடா, umbudaa,\n",
      " முச்சி muchi\n",
      " முட்டு muttu\n",
      " உம்புடா, umbudaa,\n",
      " உமே, umae,\n",
      " உமே, umae,\n",
      " உம்புடா umbudaa\n",
      "Translated tamil to tanglish text successfully\n",
      "[['umbudaa,', 1.7199999999999989, 2.2399999999999993], ['umbudaa,', 2.2399999999999993, 2.76], ['muchi', 2.86, 3.2], ['muttu', 3.2, 3.66], ['umbudaa,', 3.66, 4.36], ['umae,', 4.56, 4.88], ['umae,', 5.08, 5.28], ['umbudaa', 5.44, 5.44]]\n",
      "moottu 0\n",
      "mudtu 0\n",
      "moottoo 1\n",
      "mouttu 1\n",
      "mottu 1\n",
      "moodtu 1\n",
      "muddu 1\n",
      "mouttoo 2\n",
      "mottoo 2\n",
      "moodtoo 2\n",
      "mooottu 2\n",
      "moudtu 2\n",
      "modtu 2\n",
      "mooddu 2\n",
      "mooottoo 3\n",
      "mouttou 3\n",
      "moutto 3\n",
      "moudtoo 3\n",
      "mottou 3\n",
      "motto 3\n",
      "modtoo 3\n",
      "mooddoo 3\n",
      "mouottu 3\n",
      "mooodtu 3\n",
      "mouddu 3\n",
      "moddu 3\n",
      "mouottoo 4\n",
      "mooodtoo 4\n",
      "mooottou 4\n",
      "moudtou 4\n",
      "moootto 4\n",
      "moudto 4\n",
      "mouddoo 4\n",
      "mottooo 4\n",
      "modtou 4\n",
      "modto 4\n",
      "moddoo 4\n",
      "moooottu 4\n",
      "mouodtu 4\n",
      "moooddu 4\n",
      "moooottoo 5\n",
      "mouottou 5\n",
      "mouotto 5\n",
      "mouodtoo 5\n",
      "moooddoo 5\n",
      "mooottooo 5\n",
      "moottou 5\n",
      "mooodtou 5\n",
      "mouddou 5\n",
      "mootto 5\n",
      "mooodto 5\n",
      "mouddo 5\n",
      "mottouo 5\n",
      "modtooo 5\n",
      "moddou 5\n",
      "moddo 5\n",
      "mouoottu 5\n",
      "moooodtu 5\n",
      "mouoddu 5\n"
     ]
    }
   ],
   "source": [
    "result = transcribe_audio(clean_audio)\n",
    "print(result)\n",
    "tan_texts = []\n",
    "timestamps = []\n",
    "\n",
    "for i in result:\n",
    "    stamp = []\n",
    "    st_time = i[1]\n",
    "    en_time = i[2]\n",
    "    t = i[0]\n",
    "    tan = preprocess_text(t)\n",
    "    #print(\"preprocess: \",tan)\n",
    "    tan = trim_repeated_letters(tan)\n",
    "    tan = remove_suffix(tan)\n",
    "    #print(\"Before text: \",tan)\n",
    "    if tan not in vocab_list:\n",
    "        tan = generate_spellings(tan,vocab_list)\n",
    "    tan_texts.append(tan)\n",
    "\n",
    "    stamp.append(st_time)\n",
    "    stamp.append(en_time)\n",
    "    timestamps.append(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FYP2\\Audio_model\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hate:  ['umbu', 'umbu', 'umbu', 'umbu']\n",
      "Timestamps:  [[1.7199999999999989, 2.2399999999999993], [2.2399999999999993, 2.76], [3.66, 4.36], [5.44, 5.44]]\n",
      "Hate speech detected\n",
      "Beeped audio saved as ./Censored_audio/tempo1_censored.mp3\n"
     ]
    }
   ],
   "source": [
    "hate = []\n",
    "t_stamps = []\n",
    "for t in range(len(tan_texts)):\n",
    "\n",
    "    test_text = [tan_texts[t]]\n",
    "    cleaned = [preprocess_text(text) for text in test_text]\n",
    "    tokenized = tokenizer.tokenizer(cleaned)\n",
    "    encoded = [tokenizer.sp.PieceToId(piece) for text in tokenized for piece in text]\n",
    "    padded = pad_sequences([encoded],maxlen=70,padding=\"post\")\n",
    "\n",
    "    predictions = bilstm_model.predict(padded)\n",
    "    bilstm_label = np.argmax(predictions,axis=1)[0]\n",
    "    bilstm_conf = round(np.max(predictions),2)\n",
    "\n",
    "\n",
    "    result = predict_hate_speech(tan_texts[t],c_model,c_tokenizer,dev1)\n",
    "    bert_label = result[\"prediction\"]\n",
    "    bert_conf = round(result[\"confidence\"],2)\n",
    "\n",
    "    # print(tan_texts[t])\n",
    "    # print(bilstm_label)\n",
    "    # print(bilstm_conf)\n",
    "    # print(bert_label)\n",
    "    # print(bert_conf)\n",
    "\n",
    "    predicted_category = predict_category1(bilstm_label,bilstm_conf,bert_label,bert_conf)\n",
    "    #print(f\"{tan_texts[t]} ---> {predicted_category}\")\n",
    "\n",
    "    if(predicted_category == 1):\n",
    "        hate.append(tan_texts[t])\n",
    "        t_stamps.append(timestamps[t])\n",
    "    # if(result[\"prediction\"] == 1 and result[\"confidence\"] > 0.6):\n",
    "    #     hate.append(tan_texts[t])\n",
    "    #     t_stamps.append(timestamps[t])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Hate: \",hate)\n",
    "print(\"Timestamps: \",t_stamps)\n",
    "if(len(hate) == 0):\n",
    "    print(\"No hate speech detected\")\n",
    "else:\n",
    "    print(\"Hate speech detected\")\n",
    "\n",
    "    beep(input_audio_path,t_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
